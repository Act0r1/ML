{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моя версия реализации логистический регрессии. \n",
    "Оригинал: https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_russian/topic04_linear_models/lesson4_practice_alice_benchmarks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...               time6  site7  \\\n",
       "session_id                      ...                              \n",
       "21669                      NaT  ...                 NaT    NaN   \n",
       "54843                      NaT  ...                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ... 2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ... 2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ... 2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('../mlprojects/data/train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('../mlprojects/data/test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../mlprojects/data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n",
    "                          index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевую переменную и объединим выборки, чтобы вместе привести их к разреженному формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = full_sites_sparse[:idx_split]\n",
    "X_test_sparse = full_sites_sparse[idx_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    "    train_len = int(ratio*X.shape[0])\n",
    "    X_train = X[:train_len, :] \n",
    "    X_valid = X[train_len:, :]\n",
    "    y_train = y[:train_len]\n",
    "    y_valid = y[train_len:]\n",
    "    logit = LogisticRegression(C=C, n_jobs=-1, random_state=seed)\n",
    "    \n",
    "    logit.fit(X_train, y_train)\n",
    "    valid_pred = logit.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    return roc_auc_score(y_valid, valid_pred), logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 180 ms, total: 326 ms\n",
      "Wall time: 4.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9197957084494166, LogisticRegression(n_jobs=-1, random_state=17))"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X_train_sparse, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82797,)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse, y_train)\n",
    "test_pred = logit.predict_proba(X_test_sparse)[:,1]\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_pred, index=range(1,test_pred.shape[0]+1),name='target').to_csv('logit.csv',header=True,\n",
    "                                                                              index_label='session_id')\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id,target\r\n",
      "1,0.0022195973555361945\r\n",
      "2,2.518934875590028e-09\r\n",
      "3,6.160145453086596e-09\r\n",
      "4,1.3226767899696187e-08\r\n",
      "5,2.729074909736547e-05\r\n",
      "6,0.00015117963506244763\r\n",
      "7,0.0004423768406002131\r\n",
      "8,0.0001012456925994951\r\n",
      "9,0.0007773309339707889\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 logit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1               time2               time3  \\\n",
       "session_id                                                               \n",
       "21669      2013-01-12 08:05:57 2013-01-12 08:05:57                 NaT   \n",
       "54843      2013-01-12 08:37:23 2013-01-12 08:37:23 2013-01-12 09:07:07   \n",
       "77292      2013-01-12 08:50:13 2013-01-12 08:50:14 2013-01-12 08:50:15   \n",
       "114021     2013-01-12 08:50:17 2013-01-12 08:50:17 2013-01-12 08:50:18   \n",
       "146670     2013-01-12 08:50:20 2013-01-12 08:50:20 2013-01-12 08:50:20   \n",
       "\n",
       "                         time4               time5               time6  \\\n",
       "session_id                                                               \n",
       "21669                      NaT                 NaT                 NaT   \n",
       "54843      2013-01-12 09:07:09                 NaT                 NaT   \n",
       "77292      2013-01-12 08:50:15 2013-01-12 08:50:16 2013-01-12 08:50:16   \n",
       "114021     2013-01-12 08:50:18 2013-01-12 08:50:18 2013-01-12 08:50:18   \n",
       "146670     2013-01-12 08:50:21 2013-01-12 08:50:21 2013-01-12 08:50:21   \n",
       "\n",
       "                         time7               time8               time9  \\\n",
       "session_id                                                               \n",
       "21669                      NaT                 NaT                 NaT   \n",
       "54843                      NaT                 NaT                 NaT   \n",
       "77292      2013-01-12 08:50:16 2013-01-12 08:50:16 2013-01-12 08:50:17   \n",
       "114021     2013-01-12 08:50:19 2013-01-12 08:50:19 2013-01-12 08:50:19   \n",
       "146670     2013-01-12 08:50:21 2013-01-12 08:50:22 2013-01-12 08:50:22   \n",
       "\n",
       "                        time10  \n",
       "session_id                      \n",
       "21669                      NaT  \n",
       "54843                      NaT  \n",
       "77292      2013-01-12 08:50:17  \n",
       "114021     2013-01-12 08:50:20  \n",
       "146670     2013-01-12 08:50:22  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = ['time%d' % i for i in range(1,11)]\n",
    "train_df[time].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train = pd.DataFrame(index = train_df.index)\n",
    "new_feat_test = pd.DataFrame(index = test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train['year_month'] = train_df['time1'].apply(lambda ts:100 * ts.year + ts.month)\n",
    "new_feat_test['year_month'] = test_df['time1'].apply(lambda ts:100 * ts.year + ts.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[201301],\n",
       "       [201301],\n",
       "       [201301],\n",
       "       ...,\n",
       "       [201404],\n",
       "       [201404],\n",
       "       [201404]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_train['year_month'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(new_feat_train['year_month'].values.reshape(-1,1))\n",
    "\n",
    "new_feat_train['year_month_scaled'] = scaler.transform(new_feat_train['year_month'].values.reshape(-1,1))\n",
    "new_feat_test['year_month_scaled'] = scaler.transform(new_feat_test['year_month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "21669     201301\n",
       "54843     201301\n",
       "77292     201301\n",
       "114021    201301\n",
       "146670    201301\n",
       "Name: time1, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['time1'].apply(lambda ts:100 * ts.year + ts.month ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.74440496],\n",
       "       [-1.74440496],\n",
       "       [-1.74440496],\n",
       "       ...,\n",
       "       [ 0.68162559],\n",
       "       [ 0.68162559],\n",
       "       [ 0.68162559]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_train['year_month_scaled'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse, \n",
    "                            new_feat_train['year_month_scaled'].values.reshape(-1,1)]))\n",
    "\n",
    "#get_auc_lr_valid(X_train_sparse_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9198902054055882, LogisticRegression(n_jobs=-1, random_state=17))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (253561, 1))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, new_feat_train['year_month_scaled'].values.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train['star_hours'] = train_df['time1'].apply(lambda x : x.hour)\n",
    "new_feat_test['star_hours'] = test_df['time1'].apply(lambda x : x.hour)\n",
    "new_feat_train['morning'] = new_feat_train['star_hours'].apply(lambda x : x <= 11, 1).astype(int)\n",
    "new_feat_test['morning'] = new_feat_test['star_hours'].apply(lambda x : x <= 11, 1).astype(int)\n",
    "new_feat_train['day'] = train_df['time1'].apply(lambda x : x.day)\n",
    "new_feat_test['day'] = test_df['time1'].apply(lambda x : x.day)\n",
    "new_feat_train['star_month'] = new_feat_train['day'].apply(lambda x : x <= 10, 1).astype(int)\n",
    "new_feat_test['star_month'] = new_feat_test['day'].apply(lambda x : x <= 10, 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_feat_train.drop('day', axis=1, inplace=True)\n",
    "# new_feat_test.drop('day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем новый признак с помощью StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_feat_train['star_month'].values.reshape(-1,1))\n",
    "\n",
    "new_feat_train['star_month'] = scaler.transform(new_feat_train['star_month'].values.reshape(-1,1))\n",
    "new_feat_test['star_month'] = scaler.transform(new_feat_test['star_month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем новый признак с помощью StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_feat_train['morning'].values.reshape(-1,1))\n",
    "\n",
    "new_feat_train['morning'] = scaler.transform(new_feat_train['morning'].values.reshape(-1,1))\n",
    "new_feat_test['morning'] = scaler.transform(new_feat_test['morning'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем новый признак с помощью StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_feat_train['star_hours'].values.reshape(-1,1))\n",
    "\n",
    "new_feat_train['star_hours'] = scaler.transform(new_feat_train['star_hours'].values.reshape(-1,1))\n",
    "new_feat_test['star_hours'] = scaler.transform(new_feat_test['star_hours'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def turning_hours(data):\n",
    "#     scaler = StandardScaler()\n",
    "#     for x in range(1,11):\n",
    "#         scaler.fit(data[f'star_hour_{x}'.format(x)].values.reshape(-1,1))\n",
    "#         data[f'star_hour_{x}'.format(x)] = scaler.transform(data[f'star_hour_{x}'\\\n",
    "#                                                                                      .format(x)].values.reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82797, 6)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем всё вместе\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse, \n",
    "                            new_feat_train['morning'].values.reshape(-1,1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse, \n",
    "                            new_feat_test['morning'].values.reshape(-1,1)]))\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse, \n",
    "                            new_feat_train['star_hours'].values.reshape(-1,1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse, \n",
    "                            new_feat_test['star_hours'].values.reshape(-1,1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse, \n",
    "                            new_feat_train['star_month'].values.reshape(-1,1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse, \n",
    "                            new_feat_test['star_month'].values.reshape(-1,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9218267137158861, LogisticRegression(n_jobs=-1, random_state=17))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_merging(data):\n",
    "#     for x in range(1,11):\n",
    "#         X_train_sparse_new = X_train_sparse_new\n",
    "#         X_train_sparse_new = csr_matrix(hstack([X_train_sparse, \n",
    "#                             data[f'star_hour_{x}'.format(x)].values.reshape(-1,1)]))\n",
    "#     return X_train_sparse_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну что же , наш рез-ат увеличился на 4%. Сохраним нашу модель и отправим их в Kaggle\n",
    "logit_1 = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit_1.fit(X_train_sparse_new, y_train)\n",
    "test_pred_2 = logit_1.predict_proba(X_test_sparse_new)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_pred_2, index=range(1,test_pred.shape[0]+1),name='target').to_csv('logit_morning.csv',header=True,\n",
    "                                                                              index_label='session_id')\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9218267137158861, LogisticRegression(n_jobs=-1, random_state=17))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48372), (253561, 5))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_new.shape, new_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9218267137158861, LogisticRegression(C=1, n_jobs=-1, random_state=17))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_new, y_train, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8866524106082947, LogisticRegression(C=0.001, n_jobs=-1, random_state=17))\n",
      "(0.897604547447133, LogisticRegression(C=0.0027825594022071257, n_jobs=-1, random_state=17))\n",
      "(0.908693297297689, LogisticRegression(C=0.007742636826811269, n_jobs=-1, random_state=17))\n",
      "(0.9167066693717553, LogisticRegression(C=0.021544346900318832, n_jobs=-1, random_state=17))\n",
      "(0.921524353646858, LogisticRegression(C=0.05994842503189409, n_jobs=-1, random_state=17))\n",
      "(0.9224735499094883, LogisticRegression(C=0.1668100537200059, n_jobs=-1, random_state=17))\n",
      "(0.9215349203991454, LogisticRegression(C=0.46415888336127775, n_jobs=-1, random_state=17))\n",
      "(0.9218890575543826, LogisticRegression(C=1.2915496650148828, n_jobs=-1, random_state=17))\n",
      "(0.9226149934365373, LogisticRegression(C=3.593813663804626, n_jobs=-1, random_state=17))\n",
      "(0.9224584545490773, LogisticRegression(C=10.0, n_jobs=-1, random_state=17))\n"
     ]
    }
   ],
   "source": [
    "for C in np.logspace(-3, 1, 10):\n",
    "    print(get_auc_lr_valid(X_train_sparse_new, y_train, C = C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, C=3.5938)\n",
    "logit.fit(X_train_sparse_new, y_train)\n",
    "preds = logit.predict_proba(X_test_sparse_new)[:,1]\n",
    "pd.Series(preds, index=range(1,test_pred.shape[0]+1),name='target').to_csv('logit_finish.csv',header=True,\n",
    "                                                                              index_label='session_id')\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
